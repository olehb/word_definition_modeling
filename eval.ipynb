{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import EncoderDecoderModel, BertTokenizer\n",
    "from dataset import Oxford2019Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loc = 'models/dpp_5_epochs/'\n",
    "model_type = 'bert-base-uncased'\n",
    "data_loc = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_data_loader(filename: str, batch = 24, file_loc: str = os.path.join(data_loc, 'Oxford-2019')) -> Dataset:\n",
    "    dataset = Oxford2019Dataset(data_loc=os.path.join(file_loc, filename))\n",
    "    # data_loader = DataLoader(dataset, batch_size=batch, shuffle=True, pin_memory=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_set = make_data_loader('test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def bleu_scores(model, test_set, sample_size = None):\n",
    "    sample_ids = range(len(test_set))\n",
    "    if sample_size is not None:\n",
    "        sample_ids = random.sample(sample_ids, sample_size)\n",
    "\n",
    "    scores = []\n",
    "    for id in tqdm(sample_ids):\n",
    "        word, example, definition, _ = test_set[id]\n",
    "        input_ids = torch.tensor(tokenizer.encode(example, add_special_tokens=True)).unsqueeze(0)\n",
    "        generated = model.generate(input_ids, decoder_start_token_id=model.config.decoder.pad_token_id)\n",
    "        generated_def = tokenizer.decode(generated.squeeze(), skip_special_tokens=True)\n",
    "\n",
    "        a = generated_def.split()\n",
    "        b = definition.split()\n",
    "\n",
    "        max_length = max(len(a), len(b))\n",
    "\n",
    "        # a.extend(['<pad>']*(max_length-len(a)))\n",
    "        # b.extend(['<pad>']*(max_length-len(b)))\n",
    "\n",
    "        score = sentence_bleu(a, b)\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "\n",
    "\n",
    "def explore(model, test_set, sample_size = None):\n",
    "    sample_ids = range(len(test_set))\n",
    "    if sample_size is not None:\n",
    "        sample_ids = random.sample(sample_ids, sample_size)\n",
    "\n",
    "    result = []\n",
    "    for id in tqdm(sample_ids):\n",
    "        word, example, definition, _ = test_set[id]\n",
    "        input_ids = torch.tensor(tokenizer.encode(example, add_special_tokens=True)).unsqueeze(0)\n",
    "        generated = model.generate(input_ids, decoder_start_token_id=model.config.decoder.pad_token_id)\n",
    "        generated_def = tokenizer.decode(generated.squeeze(), skip_special_tokens=True)\n",
    "\n",
    "        result.append((word, generated_def, definition))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'bleu_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-9-ca2a513b6da2>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mbleu_scores_5_epochs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbleu_scores\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_set\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;36m100\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ms\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0ms\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mbleu_scores_5_epochs\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0ms\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-7-28558b339ca4>\u001B[0m in \u001B[0;36mbleu_scores\u001B[0;34m(model, test_set)\u001B[0m\n\u001B[1;32m     14\u001B[0m         \u001B[0mb\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'<pad>'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmax_length\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 16\u001B[0;31m         \u001B[0mscore\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbleu_score\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     17\u001B[0m         \u001B[0mscores\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mscore\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mscores\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'bleu_score' is not defined"
     ]
    }
   ],
   "source": [
    "model = EncoderDecoderModel.from_pretrained(model_loc)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:07<01:36,  1.04s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-57-d230277bd1ae>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mbleu_scores_5_epochs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbleu_scores\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_set\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;36m100\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ms\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0ms\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mbleu_scores_5_epochs\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0ms\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-56-fc89cd7b6482>\u001B[0m in \u001B[0;36mbleu_scores\u001B[0;34m(model, test_set)\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mword\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexample\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdefinition\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_set\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m         \u001B[0minput_ids\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtokenizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mencode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexample\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0madd_special_tokens\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m         \u001B[0mgenerated\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgenerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_ids\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdecoder_start_token_id\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecoder\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpad_token_id\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m         \u001B[0mgenerated_def\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtokenizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgenerated\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mskip_special_tokens\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/oboiko/opt/miniconda3/envs/S37/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001B[0m in \u001B[0;36mdecorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0;31m`\u001B[0m\u001B[0mrequires_grad\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0meven\u001B[0m \u001B[0mwhen\u001B[0m \u001B[0mthe\u001B[0m \u001B[0minputs\u001B[0m \u001B[0mhave\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0mrequires_grad\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m     \u001B[0mThis\u001B[0m \u001B[0mmode\u001B[0m \u001B[0mhas\u001B[0m \u001B[0mno\u001B[0m \u001B[0meffect\u001B[0m \u001B[0mwhen\u001B[0m \u001B[0musing\u001B[0m \u001B[0;34m:\u001B[0m\u001B[0;32mclass\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;34m~\u001B[0m\u001B[0menable_grad\u001B[0m\u001B[0;31m`\u001B[0m \u001B[0mcontext\u001B[0m \u001B[0mmanager\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m     \u001B[0mThis\u001B[0m \u001B[0mcontext\u001B[0m \u001B[0mmanager\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0mthread\u001B[0m \u001B[0mlocal\u001B[0m\u001B[0;34m;\u001B[0m \u001B[0mit\u001B[0m \u001B[0mwill\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0maffect\u001B[0m \u001B[0mcomputation\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/oboiko/opt/miniconda3/envs/S37/lib/python3.7/site-packages/transformers/generation_utils.py\u001B[0m in \u001B[0;36mgenerate\u001B[0;34m(self, input_ids, decoder_input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, num_return_sequences, attention_mask, decoder_start_token_id, use_cache, **model_kwargs)\u001B[0m\n\u001B[1;32m    507\u001B[0m                 \u001B[0mattention_mask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mattention_mask\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    508\u001B[0m                 \u001B[0muse_cache\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0muse_cache\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 509\u001B[0;31m                 \u001B[0mmodel_kwargs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmodel_kwargs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    510\u001B[0m             )\n\u001B[1;32m    511\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/oboiko/opt/miniconda3/envs/S37/lib/python3.7/site-packages/transformers/generation_utils.py\u001B[0m in \u001B[0;36m_generate_no_beam_search\u001B[0;34m(self, input_ids, cur_len, max_length, min_length, do_sample, temperature, top_k, top_p, repetition_penalty, no_repeat_ngram_size, bad_words_ids, pad_token_id, eos_token_id, batch_size, attention_mask, use_cache, model_kwargs)\u001B[0m\n\u001B[1;32m    545\u001B[0m             )\n\u001B[1;32m    546\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 547\u001B[0;31m             \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mmodel_inputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreturn_dict\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    548\u001B[0m             \u001B[0mnext_token_logits\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlogits\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    549\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/oboiko/opt/miniconda3/envs/S37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    720\u001B[0m                 \u001B[0mpersistent\u001B[0m \u001B[0mbuffers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    721\u001B[0m             \u001B[0mprefix\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mprefix\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mparameters\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mbuffers\u001B[0m \u001B[0mused\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mthis\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 722\u001B[0;31m                 \u001B[0mmodule\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    723\u001B[0m             \u001B[0mlocal_metadata\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mdict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0ma\u001B[0m \u001B[0mdict\u001B[0m \u001B[0mcontaining\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mmetadata\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mthis\u001B[0m \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    724\u001B[0m                 \u001B[0mSee\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/oboiko/opt/miniconda3/envs/S37/lib/python3.7/site-packages/transformers/modeling_encoder_decoder.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001B[0m\n\u001B[1;32m    417\u001B[0m             \u001B[0moutput_hidden_states\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moutput_hidden_states\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    418\u001B[0m             \u001B[0mreturn_dict\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mreturn_dict\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 419\u001B[0;31m             \u001B[0;34m**\u001B[0m\u001B[0mkwargs_decoder\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    420\u001B[0m         )\n\u001B[1;32m    421\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/oboiko/opt/miniconda3/envs/S37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    720\u001B[0m                 \u001B[0mpersistent\u001B[0m \u001B[0mbuffers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    721\u001B[0m             \u001B[0mprefix\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mprefix\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mparameters\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mbuffers\u001B[0m \u001B[0mused\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mthis\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 722\u001B[0;31m                 \u001B[0mmodule\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    723\u001B[0m             \u001B[0mlocal_metadata\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mdict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0ma\u001B[0m \u001B[0mdict\u001B[0m \u001B[0mcontaining\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mmetadata\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mthis\u001B[0m \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    724\u001B[0m                 \u001B[0mSee\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/oboiko/opt/miniconda3/envs/S37/lib/python3.7/site-packages/transformers/modeling_bert_generation.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    487\u001B[0m             \u001B[0moutput_attentions\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moutput_attentions\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    488\u001B[0m             \u001B[0moutput_hidden_states\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moutput_hidden_states\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 489\u001B[0;31m             \u001B[0mreturn_dict\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mreturn_dict\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    490\u001B[0m         )\n\u001B[1;32m    491\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/oboiko/opt/miniconda3/envs/S37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    720\u001B[0m                 \u001B[0mpersistent\u001B[0m \u001B[0mbuffers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    721\u001B[0m             \u001B[0mprefix\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mprefix\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mparameters\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mbuffers\u001B[0m \u001B[0mused\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mthis\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 722\u001B[0;31m                 \u001B[0mmodule\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    723\u001B[0m             \u001B[0mlocal_metadata\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mdict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0ma\u001B[0m \u001B[0mdict\u001B[0m \u001B[0mcontaining\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mmetadata\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mthis\u001B[0m \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    724\u001B[0m                 \u001B[0mSee\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/oboiko/opt/miniconda3/envs/S37/lib/python3.7/site-packages/transformers/modeling_bert_generation.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    378\u001B[0m             \u001B[0moutput_attentions\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moutput_attentions\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    379\u001B[0m             \u001B[0moutput_hidden_states\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moutput_hidden_states\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 380\u001B[0;31m             \u001B[0mreturn_dict\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mreturn_dict\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    381\u001B[0m         )\n\u001B[1;32m    382\u001B[0m         \u001B[0msequence_output\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mencoder_outputs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/oboiko/opt/miniconda3/envs/S37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    720\u001B[0m                 \u001B[0mpersistent\u001B[0m \u001B[0mbuffers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    721\u001B[0m             \u001B[0mprefix\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mprefix\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mparameters\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mbuffers\u001B[0m \u001B[0mused\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mthis\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 722\u001B[0;31m                 \u001B[0mmodule\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    723\u001B[0m             \u001B[0mlocal_metadata\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mdict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0ma\u001B[0m \u001B[0mdict\u001B[0m \u001B[0mcontaining\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mmetadata\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mthis\u001B[0m \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    724\u001B[0m                 \u001B[0mSee\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/oboiko/opt/miniconda3/envs/S37/lib/python3.7/site-packages/transformers/modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    480\u001B[0m                     \u001B[0mencoder_hidden_states\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    481\u001B[0m                     \u001B[0mencoder_attention_mask\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 482\u001B[0;31m                     \u001B[0moutput_attentions\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    483\u001B[0m                 )\n\u001B[1;32m    484\u001B[0m             \u001B[0mhidden_states\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlayer_outputs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/oboiko/opt/miniconda3/envs/S37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    720\u001B[0m                 \u001B[0mpersistent\u001B[0m \u001B[0mbuffers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    721\u001B[0m             \u001B[0mprefix\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mprefix\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mparameters\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mbuffers\u001B[0m \u001B[0mused\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mthis\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 722\u001B[0;31m                 \u001B[0mmodule\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    723\u001B[0m             \u001B[0mlocal_metadata\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mdict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0ma\u001B[0m \u001B[0mdict\u001B[0m \u001B[0mcontaining\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mmetadata\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mthis\u001B[0m \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    724\u001B[0m                 \u001B[0mSee\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/oboiko/opt/miniconda3/envs/S37/lib/python3.7/site-packages/transformers/modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001B[0m\n\u001B[1;32m    421\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    422\u001B[0m         layer_output = apply_chunking_to_forward(\n\u001B[0;32m--> 423\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfeed_forward_chunk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchunk_size_feed_forward\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mseq_len_dim\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mattention_output\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    424\u001B[0m         )\n\u001B[1;32m    425\u001B[0m         \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mlayer_output\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/oboiko/opt/miniconda3/envs/S37/lib/python3.7/site-packages/transformers/modeling_utils.py\u001B[0m in \u001B[0;36mapply_chunking_to_forward\u001B[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001B[0m\n\u001B[1;32m   1694\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutput_chunks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mchunk_dim\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1695\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1696\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mforward_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput_tensors\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/Users/oboiko/opt/miniconda3/envs/S37/lib/python3.7/site-packages/transformers/modeling_bert.py\u001B[0m in \u001B[0;36mfeed_forward_chunk\u001B[0;34m(self, attention_output)\u001B[0m\n\u001B[1;32m    428\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mfeed_forward_chunk\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mattention_output\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    429\u001B[0m         \u001B[0mintermediate_output\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mintermediate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mattention_output\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 430\u001B[0;31m         \u001B[0mlayer_output\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moutput\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mintermediate_output\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mattention_output\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    431\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mlayer_output\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    432\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/oboiko/opt/miniconda3/envs/S37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    720\u001B[0m                 \u001B[0mpersistent\u001B[0m \u001B[0mbuffers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    721\u001B[0m             \u001B[0mprefix\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mprefix\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mparameters\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mbuffers\u001B[0m \u001B[0mused\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mthis\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 722\u001B[0;31m                 \u001B[0mmodule\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    723\u001B[0m             \u001B[0mlocal_metadata\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mdict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0ma\u001B[0m \u001B[0mdict\u001B[0m \u001B[0mcontaining\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mmetadata\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mthis\u001B[0m \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    724\u001B[0m                 \u001B[0mSee\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/oboiko/opt/miniconda3/envs/S37/lib/python3.7/site-packages/transformers/modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, hidden_states, input_tensor)\u001B[0m\n\u001B[1;32m    367\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    368\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhidden_states\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput_tensor\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 369\u001B[0;31m         \u001B[0mhidden_states\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdense\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhidden_states\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    370\u001B[0m         \u001B[0mhidden_states\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhidden_states\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    371\u001B[0m         \u001B[0mhidden_states\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mLayerNorm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhidden_states\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0minput_tensor\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/oboiko/opt/miniconda3/envs/S37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    720\u001B[0m                 \u001B[0mpersistent\u001B[0m \u001B[0mbuffers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    721\u001B[0m             \u001B[0mprefix\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mprefix\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mparameters\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mbuffers\u001B[0m \u001B[0mused\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mthis\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 722\u001B[0;31m                 \u001B[0mmodule\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    723\u001B[0m             \u001B[0mlocal_metadata\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mdict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0ma\u001B[0m \u001B[0mdict\u001B[0m \u001B[0mcontaining\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mmetadata\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mthis\u001B[0m \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    724\u001B[0m                 \u001B[0mSee\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/oboiko/opt/miniconda3/envs/S37/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m     89\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mextra_repr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     90\u001B[0m         return 'in_features={}, out_features={}, bias={}'.format(\n\u001B[0;32m---> 91\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0min_features\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mout_features\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     92\u001B[0m         )\n\u001B[1;32m     93\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Users/oboiko/opt/miniconda3/envs/S37/lib/python3.7/site-packages/torch/nn/functional.py\u001B[0m in \u001B[0;36mlinear\u001B[0;34m(input, weight, bias)\u001B[0m\n\u001B[1;32m   1674\u001B[0m def instance_norm(input, running_mean=None, running_var=None, weight=None,\n\u001B[1;32m   1675\u001B[0m                   bias=None, use_input_stats=True, momentum=0.1, eps=1e-5):\n\u001B[0;32m-> 1676\u001B[0;31m     \u001B[0;31m# type: (Tensor, Optional[Tensor], Optional[Tensor], Optional[Tensor], Optional[Tensor], bool, float, float) -> Tensor  # noqa\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1677\u001B[0m     r\"\"\"Applies Instance Normalization for each channel in each data sample in a\n\u001B[1;32m   1678\u001B[0m     \u001B[0mbatch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "bleu_scores_5_epochs = bleu_scores(model, test_set[:100])\n",
    "sum((s for s in bleu_scores_5_epochs if s != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_10_epochs = EncoderDecoderModel.from_pretrained('models/dpp_10_epochs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('anaemic', 'a person who is not in the same way', 'suffering from anaemia'),\n",
       " ('anaemic', 'a person who is not in the same way', 'suffering from anaemia'),\n",
       " ('horde',\n",
       "  'a person who is a person who is a person who is not a person who is not a',\n",
       "  'an army or tribe of nomadic warriors'),\n",
       " ('horde',\n",
       "  'a person who is a person who is a person who is not a person who is not a',\n",
       "  'an army or tribe of nomadic warriors'),\n",
       " ('horde',\n",
       "  'a person who is a person who is a person who is not a person who is not a',\n",
       "  'an army or tribe of nomadic warriors'),\n",
       " ('order',\n",
       "  'a person who is a person who is a religious church',\n",
       "  'a society of knights bound by a common rule of life and having a combined military and monastic character'),\n",
       " ('order',\n",
       "  'a person who is a person who is a religious church',\n",
       "  'a society of knights bound by a common rule of life and having a combined military and monastic character'),\n",
       " ('order',\n",
       "  'a person who is a person who is a religious church',\n",
       "  'a society of knights bound by a common rule of life and having a combined military and monastic character'),\n",
       " ('ringleader',\n",
       "  'a person who is a person who is a person who is not a person who is not a',\n",
       "  'a person who initiates or leads an illicit or illegal activity'),\n",
       " ('ringleader',\n",
       "  'a person who is a person who is a person who is not a person who is not a',\n",
       "  'a person who initiates or leads an illicit or illegal activity')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explore(model_10_epochs, test_set[10:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:30<00:00,  1.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_scores_10_epochs = bleu_scores(model_10_epochs, test_set[:100])\n",
    "sum((s for s in bleu_scores_10_epochs if s != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_20_epochs = EncoderDecoderModel.from_pretrained('models/dpp_20_epochs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "[('aesthetically',\n  'of a person having a particular quality',\n  'with regard to beauty'),\n ('monody',\n  'a musical instrument with a long, narrow neck, used for playing music or music in a particular',\n  'an ode sung by a single actor in a greek tragedy'),\n ('caress',\n  'a small, narrow, narrow piece of something',\n  'touch or stroke gently or lovingly'),\n ('library',\n  'a book or other item of information that is used to provide a particular information',\n  'a collection of films , recorded music , etc , organized systematically and kept for research or borrowing'),\n ('dura',\n  'a small, narrow piece of material, typically one that is attached to the body of a person',\n  'the tough outermost membrane enveloping the brain and spinal cord'),\n ('stick',\n  'make a person or animal more attractive or attractive',\n  'adhere or cling to something'),\n ('waistline',\n  \"a narrow strip of cloth or other material used to cover a person's body\",\n  \"the measurement around a person 's body at the waist\"),\n ('usher', 'a person who makes or sells goods', 'an assistant teacher'),\n ('victimization',\n  'a person who is a member of a group',\n  'the action of singling someone out for cruel or unjust treatment'),\n ('pesticide',\n  'a person who makes or sells goods, especially goods for sale',\n  'a substance used for destroying insects or other organisms harmful to cultivated plants or to animals'),\n ('ferricyanide',\n  'a substance which is used to make a substance or material that is used to make a substance more',\n  'a salt containing the anion fe cn'),\n ('cynicism',\n  'a person who is not a member of a particular group or group',\n  'an inclination to question whether something will happen or whether it is worthwhile'),\n ('consumer',\n  'a person who makes or sells goods',\n  'a person who purchases goods and services for personal use'),\n ('disposition',\n  'a person who is a member of a military force',\n  'the action of arranging people or things in a particular way'),\n ('resemble',\n  'a small, thin, thin, thin piece of something, especially a piece of material',\n  'have a similar appearance to or qualities in common with someone or something'),\n ('capitulate',\n  'a person who is able to do something',\n  'cease to resist an opponent or an unwelcome demand'),\n ('waypoint',\n  'a person who is a member of a particular group, especially a political one',\n  'a stopping place on a journey'),\n ('fornicate',\n  'a person who is not a member of a particular group or group',\n  'have sexual intercourse with someone one is not married to'),\n ('home',\n  'a person who is able to do something',\n  'relating to the place where one lives'),\n ('repertory',\n  'a person who is a member of a particular group',\n  'a repository or collection , especially of information')]"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explore(model_20_epochs, test_set, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [16:06<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.595307732167172e-232\n"
     ]
    }
   ],
   "source": [
    "sample_size = 1000\n",
    "bleu_scores_20_epochs = bleu_scores(model_20_epochs, test_set, sample_size)\n",
    "print(sum(bleu_scores_20_epochs) / float(sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "model_20_epochs_large_lr = EncoderDecoderModel.from_pretrained('models/dpp_20_epochs_high_lr')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "[('puppetry',\n  'the the the the the the the the the the the the the the the the the the the',\n  'pretence'),\n ('gyp',\n  'a a a a a a a a a a a a a a a a a a a',\n  'an act of cheating someone'),\n ('gyp',\n  'a a a a a a a a a a a a a a a a a a a',\n  'an act of cheating someone'),\n ('gyp',\n  'a a a a a a a a a a a a a a a a a a a',\n  'an act of cheating someone'),\n ('interdisciplinary',\n  'having having having having having having having having having having having having having having having having having having having',\n  'relating to more than one branch of knowledge'),\n ('interdisciplinary',\n  'having having having having having having having having having having having having having having having having having having having',\n  'relating to more than one branch of knowledge'),\n ('interdisciplinary',\n  'having having having having having having having having having having having having having having having having having having having',\n  'relating to more than one branch of knowledge'),\n ('adventuress',\n  'a a a a a a a a a a a a a a a a a a a',\n  'a female adventurer'),\n ('adventuress',\n  'a a a a a a a a a a a a a a a a a a a',\n  'a female adventurer'),\n ('adventuress',\n  'a a a a a a a a a a a a a a a a a a a',\n  'a female adventurer'),\n ('billet',\n  'a a a a a a a a a a a a a a a a a a a',\n  'each of a series of short cylindrical pieces inserted at intervals in norman decorative mouldings'),\n ('billet',\n  'a a a a a a a a a a a a a a a a a a a',\n  'each of a series of short cylindrical pieces inserted at intervals in norman decorative mouldings'),\n ('billet',\n  'a a a a a a a a a a a a a a a a a a a',\n  'each of a series of short cylindrical pieces inserted at intervals in norman decorative mouldings'),\n ('alteration',\n  'the the the the the the the the the the the the the the the the the the the',\n  'the action or process of altering or being altered'),\n ('alteration',\n  'the the the the the the the the the the the the the the the the the the the',\n  'the action or process of altering or being altered'),\n ('alteration',\n  'the the the the the the the the the the the the the the the the the the the',\n  'the action or process of altering or being altered'),\n ('alteration',\n  'the the the the the the the the the the the the the the the the the the the',\n  'the action or process of altering or being altered'),\n ('alteration',\n  'the the the the the the the the the the the the the the the the the the the',\n  'the action or process of altering or being altered'),\n ('alteration',\n  'the the the the the the the the the the the the the the the the the the the',\n  'the action or process of altering or being altered'),\n ('goby',\n  'a a a a a a a a a a a a a a a a a a a',\n  'a small , usually marine fish that typically has a sucker on the underside')]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explore(model_20_epochs_large_lr, test_set[60:80])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}