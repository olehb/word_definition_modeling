{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install loguru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import (EncoderDecoderModel,\n",
    "                          PreTrainedModel,\n",
    "                          BertTokenizer,\n",
    "                          BertGenerationEncoder,\n",
    "                          BertGenerationDecoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.add(\"log.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Determining device to run on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    main_device = torch.device(\"cuda:0\")\n",
    "    device_count = torch.cuda.device_count()\n",
    "    if device_count > 1:\n",
    "        src_device = torch.device(\"cuda:1\")\n",
    "    else:\n",
    "        src_device = main_device\n",
    "        \n",
    "    logger.info(\"Running on the GPU\", main_device)\n",
    "else:\n",
    "    main_device = torch.device(\"cpu\")\n",
    "    src_device = torch.device(\"cpu\")\n",
    "    device_count = 1\n",
    "    logger.info(\"Running on the CPU\", main_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Reading hyperparameters from SageMaker env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_type = os.environ.get('SM_HP_MODEL_TYPE', 'bert-base-uncased')\n",
    "data_loc = os.environ.get('SM_HP_DATA_LOC', '../data')\n",
    "epochs = int(os.environ.get('SM_HP_EPOCHS', 2))\n",
    "batch = int(os.environ.get('SM_HP_BATCH', 32)) * device_count\n",
    "lr = float(os.environ.get('SM_HP_LR', 1e-5))\n",
    "train_remotely = bool(int(os.environ.get('SM_HP_TRAIN_REMOTELY', 1)))\n",
    "is_sagemaker_estimator = 'TRAINING_JOB_NAME' in os.environ  # This code is running on the remote SageMaker estimator machine\n",
    "\n",
    "notebook_name = os.environ['SM_HP_NOTEBOOK_NAME'] if is_sagemaker_estimator else ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BOS_TOKEN_ID = 101\n",
    "EOS_TOKEN_ID = 102"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Initializing data loaders for Oxford2019 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from dataset import Oxford2019Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def make_data_loader(filename: str, file_loc: str = os.path.join(data_loc, 'Oxford-2019')) -> DataLoader:\n",
    "    dataset = Oxford2019Dataset(data_loc=os.path.join(file_loc, filename))\n",
    "    data_loader = DataLoader(dataset, batch_size=batch, shuffle=True, pin_memory=True)\n",
    "    return data_loader\n",
    "\n",
    "train_set = make_data_loader('train.txt')\n",
    "test_set = make_data_loader('test.txt')\n",
    "valid_set = make_data_loader('valid.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to run through one epoch\n",
    "This function is used in training, validation, and testing phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "def run(model: nn.Module,\n",
    "        data_loader: DataLoader,\n",
    "        tokenizer: BertTokenizer,\n",
    "        post_hook: Callable = lambda i, b: ''):\n",
    "\n",
    "    loss = 0\n",
    "    for i, (words, examples, defs, _) in enumerate(tqdm(data_loader, disable=is_sagemaker_estimator)):\n",
    "        input_ids = tokenizer(examples,\n",
    "                              add_special_tokens=False,\n",
    "                              padding=True,\n",
    "                              truncation=True,\n",
    "                              return_tensors=\"pt\").input_ids\n",
    "        output_ids = tokenizer(defs,\n",
    "                               padding=True,\n",
    "                               truncation=True,\n",
    "                               return_tensors=\"pt\").input_ids\n",
    "        \n",
    "        input_ids = input_ids.to(src_device)\n",
    "        output_ids = output_ids.to(src_device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids,\n",
    "                        decoder_input_ids=output_ids,\n",
    "                        labels=output_ids,\n",
    "                        return_dict=True)\n",
    "        batch_loss = outputs.loss.sum()\n",
    "        loss += batch_loss.item()\n",
    "\n",
    "        post_hook(i, batch_loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "def train(epochs: int, train_data_loader: DataLoader, valid_data_loader: DataLoader = None, model: nn.Module = None):\n",
    "    if model is None:\n",
    "        encoder = BertGenerationEncoder.from_pretrained(model_type,\n",
    "                                                        bos_token_id=BOS_TOKEN_ID,\n",
    "                                                        eos_token_id=EOS_TOKEN_ID) # add cross attention layers and use BERT’s cls token as BOS token and sep token as EOS token\n",
    "\n",
    "        decoder = BertGenerationDecoder.from_pretrained(model_type,\n",
    "                                                        add_cross_attention=True,\n",
    "                                                        is_decoder=True,\n",
    "                                                        bos_token_id=BOS_TOKEN_ID,\n",
    "                                                        eos_token_id=EOS_TOKEN_ID)\n",
    "        model = EncoderDecoderModel(encoder=encoder, decoder=decoder).to(src_device)\n",
    "        model = nn.DataParallel(model, \n",
    "                                device_ids=list(range(1, torch.cuda.device_count())), \n",
    "                                output_device=0)\n",
    "\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_type)\n",
    "    \n",
    "\n",
    "    def update_weights(i, batch_loss):\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            logger.info(f'batch_error={batch_loss.item()};')\n",
    "\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = run(model, train_data_loader, tokenizer, update_weights)\n",
    "\n",
    "        if valid_data_loader is not None:\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                val_loss = run(model, valid_data_loader, tokenizer)\n",
    "        else:\n",
    "            val_loss = 'N/A'\n",
    "        \n",
    "        logger.info(f'train_error={train_loss};  valid_error={val_loss};')\n",
    "    return model.module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model: PreTrainedModel):\n",
    "    out_loc = '/opt/ml/model' if is_sagemaker_estimator else '.'\n",
    "    !mkdir -p {out_loc}\n",
    "\n",
    "    model.save_pretrained(out_loc)\n",
    "\n",
    "    !cp {notebook_name}.py {out_loc}\n",
    "    !cp {notebook_name}.ipynb {out_loc}\n",
    "    !cp log.txt {out_loc}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick sanity check for the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not is_sagemaker_estimator:\n",
    "#     encoder = BertGenerationEncoder.from_pretrained(model_type,\n",
    "#                                                     bos_token_id=BOS_TOKEN_ID,\n",
    "#                                                     eos_token_id=EOS_TOKEN_ID) # add cross attention layers and use BERT’s cls token as BOS token and sep token as EOS token\n",
    "\n",
    "#     decoder = BertGenerationDecoder.from_pretrained(model_type,\n",
    "#                                                     add_cross_attention=True,\n",
    "#                                                     is_decoder=True,\n",
    "#                                                     bos_token_id=BOS_TOKEN_ID,\n",
    "#                                                     eos_token_id=EOS_TOKEN_ID)\n",
    "#     model = EncoderDecoderModel(encoder=encoder, decoder=decoder).to(device)    \n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    train_file = os.path.join(data_loc, 'Oxford-2019', 'train.txt')\n",
    "    tiny_size = batch * 5\n",
    "    tiny_file = os.path.join(data_loc, 'Oxford-2019', 'tiny.txt')\n",
    "    !head -n {tiny_size} {train_file} > {tiny_file}\n",
    "    tiny_set = make_data_loader('tiny.txt')\n",
    "    model = train(epochs=1, train_data_loader=tiny_set, valid_data_loader=tiny_set)\n",
    "    save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_sagemaker_estimator:\n",
    "    model.eval()\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    input_ids = torch.tensor(tokenizer.encode(\"Basketball Basketball's early adherents were dispatched to YMCAs throughout the United States, and it quickly spread through the United States and Canada\", add_special_tokens=True)).unsqueeze(0).to(src_device)\n",
    "    generated = model.generate(input_ids, decoder_start_token_id=model.config.decoder.pad_token_id)\n",
    "    print(tokenizer.decode(generated.squeeze(), skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "Training can be done either on the same machine where notebook is running or remotely on SageMaker estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "if is_sagemaker_estimator:\n",
    "    model = train(epochs=epochs, train_data_loader=train_set, valid_data_loader=valid_set)\n",
    "    save_model(model)\n",
    "elif train_remotely:\n",
    "    role = sagemaker.get_execution_role()\n",
    "    output_path = f's3://chegg-ds-data/oboiko/wdm-output'\n",
    "\n",
    "    pytorch_estimator = PyTorch(entry_point='train.sh',\n",
    "                                base_job_name='wdm-1',\n",
    "                                role=role,\n",
    "                                train_instance_count=1,\n",
    "                                train_instance_type='ml.p2.8xlarge',  # GPU instance\n",
    "                                train_volume_size=50,\n",
    "                                train_max_run=86400,  # 24 hours\n",
    "                                hyperparameters={\n",
    "                                  'model_type': 'bert-base-uncased',\n",
    "                                  'data_loc': '/opt/data',\n",
    "                                  'batch': 32,\n",
    "                                  'epochs': 10,\n",
    "                                  'lr': 1e-5,\n",
    "                                  'train_remotely': 0,\n",
    "                                  'notebook_name': 'main_bert_distributed'\n",
    "                                },\n",
    "                                framework_version='1.6.0',\n",
    "                                py_version='py3',\n",
    "                                source_dir='.',  # This entire folder will be transferred to training instance\n",
    "                                debugger_hook_config=False,\n",
    "                                output_path=output_path,  # Model files will be uploaded here\n",
    "                                image_name='954558792927.dkr.ecr.us-west-2.amazonaws.com/sagemaker/wdm:latest',\n",
    "                                metric_definitions=[\n",
    "                                    {'Name': 'train:error', 'Regex': 'train_error=(.*?);'},\n",
    "                                    {'Name': 'validation:error', 'Regex': 'valid_error=(.*?);'},\n",
    "                                    {'Name': 'batch:error', 'Regex': 'batch_error=(.*?);'}\n",
    "                                ]\n",
    "                     )\n",
    "\n",
    "    pytorch_estimator.fit('s3://chegg-ds-data/oboiko/wdm/dummy.txt', wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: For loss function... instead of doing log_softmax, do MSE with actual GloVe vector and minimize this loss function.\n",
    "Then for BLEU evaluation, you'll need a function to find the closest vector to the one produced by the model.\n",
    "\n",
    "Interesting to compare these results to log_softmax"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "146.989px",
    "width": "305px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
